\section{Conclusion}
In this paper, we introduced the Masked Temporal Interpolation Diffusion (MTID) model, specifically designed for procedure planning in instructional videos. Our model employs a latent space temporal interpolation module within a U-Net architecture to capture intermediate states and temporal relationships between actions. By incorporating a task-adaptive masked strategy during both inference and loss calculation, MTID improves the accuracy and consistency of generated action sequences. Extensive experiments across the CrossTask, COIN, and NIV datasets demonstrate that our model consistently outperforms existing methods on key metrics.
For future work, we aim to further optimize the memory efficiency of the model to handle larger datasets more effectively. Additionally, refining the mask mechanism to enhance control over intermediate state generation and exploring more diverse interpolation strategies remain promising directions. We also plan to extend the application of the temporal interpolation module to broader procedural learning tasks, including more complex conditional planning scenarios.

\section*{Appendix}
\appendix
\section{Implementation Details}
\subsection{Model Architecture Details} 

In the first learning stage, we aim to predict the task class label given the observations $\left\{V_s, V_g\right\}$. We employ a simple 4-layer transformer model for this task and use cross-entropy loss to train the model by comparing its output with the ground truth task class labels.

The classifier is a neural network based on the transformer architecture. It first embeds the input data through a linear layer, after which the embedded data is processed by multiple stacked transformer encoder layers. The output of the encoder layers is averaged and then passed through a series of fully connected layers with ReLU activation functions. Finally, the processed data is passed through a linear layer to generate the final output. Dropout layers are applied throughout the model to prevent overfitting. 

Next, our main model is based on a 3-layer U-Net~\citep{ronneberger2015u}, similar to \citet{wang2023pdpp}, but adapted for temporal action prediction. Each layer consists of two residual temporal blocks~\citep{he2016deep}, followed by either downsampling or upsampling. Each residual temporal block includes two convolutional layers, group normalization~\citep{wu2018group}, Mish activation~\citep{misra2019mish}, and a cross-attention module for feature fusion. Temporal embeddings are generated via a fully connected layer and added to the output of the first convolution. To handle the short planning horizon ($T = \{3, 4, 5, 6\}$), we employ 1D convolutions with a kernel size of 2, stride of 1, and no padding for downsampling/upsampling used by \citet{wang2023pdpp}, instead of the max-pooling approach, ensuring the horizon length remains unchanged. The middle block consists of only two residual temporal blocks.

The input matrix $\hat{x}_n$ is a concatenation of the task class, action sequences, and observation features, with a dimension of $fusion\_dim = C + A + O$, where $C$, $A$, and $O$ represent the number of task classes, action labels, and visual features, respectively. During the downsampling phase, the input is embedded through $[fusion\_dim \to 256 \to 512 \to 1024]$, with the reverse process occurring during the upsampling phase.

The latent space temporal interpolation module consists of three main components: an observation encoder, a latent space interpolator, and transformer encoder blocks. The observation encoder reduces the input dimensionality using two 1D convolutional layers with ReLU activations. The latent space interpolator generates intermediate features between two encoded representations via linear interpolation, guided by a learnable linear layer initialized with matrix $\tau$. The generated matrix is passed through a Sigmoid function to compute $I_j$. Finally, standard transformer encoder blocks apply attention mechanisms to enhance the temporal relationships in $F_j$, ultimately producing transformed latent features with a shape of $[M, O]$, where $M$ refers to the number of residual temporal blocks in the U-Net.


For the diffusion process, we employ a cosine noise schedule to generate $\{\beta_n\}_{n=1}^N$, which controls the amount of noise added at each step. These values correspond to the variance of the Gaussian noise introduced at each stage of diffusion.


\subsection{Dataset Details} 
Each video in the dataset is annotated with action labels and their corresponding temporal boundaries, denoted as $\{s_i, e_i\}$ for the $i$-th action, where $s_i$ and $e_i$ represent the start and end times, respectively. The total number of actions in the dataset is denoted as $Num$. We extract step sequences $a_{t:(t+T-1)}$ from the videos, with the horizon $T$ ranging from 3 to 6. Following the method in previous work~\citep{wang2023pdpp}, action sequences $\{[a_t, \ldots, a_{t+T-1}]\}_{t=1}^{Num-T+1}$ are generated by sliding a window of size $T$ over the $Num$ actions. For each sequence, the video clip feature at the start time of action $a_t$ is used as the starting observation $V_s$, and the clip feature at the end time of action $a_{t+T-1}$ is used as the goal state $V_g$. Both clips are 3 seconds in duration. The start and end times of each sequence are rounded to $\lfloor s_t \rfloor$ and $\lceil e_{t+T-1} \rceil$, respectively, with the clip features between these times used as $V_s$ and $V_g$.

For the CrossTask dataset, we consider two types of pre-extracted features: (1) the 3200-dimensional features provided by the dataset, which combine I3D, ResNet-152, and audio VGG features~\citep{carreira2017quo,he2016deep,hershey2017cnn}, and (2) features extracted using an encoder trained on the HowTo100M dataset~\citep{miech2019howto100m}, as used in~\citep{wang2023pdpp}. We utilize the latter due to its smaller size. For the COIN and NIV datasets, we also use HowTo100M features~\citep{wang2023pdpp} to maintain consistency and ensure fair comparison.



\subsection{Details of Metrics }
Previous works~\citep{chang2020procedure, bi2021procedure, sun2022plate} computed the mIoU metric over mini-batches, averaging the results across the batch size. However, this method introduces variability depending on the batch size. For instance, if the batch size equals the entire dataset, all predicted actions may be considered correct. In contrast, using a batch size of one penalizes any mismatch between predicted and ground-truth sequences. To address this issue, we follow \citet{wang2023pdpp} by standardizing mIoU calculation, computing it for each individual sequence and then averaging the results, effectively treating the batch size as one. However, this approach may result in our mIoU scores being lower than those reported by others.


\subsection{Training Details} 
Following \citet{wang2023pdpp}, we employ a linear warm-up strategy to train our model, with specific protocols adjusted for different datasets. For the CrossTask dataset, we set the diffusion steps to 250 and train for 20,000 steps. The learning rate is linearly increased to \(5 \times 10^{-4}\) over the first 3,333 steps, then halved at steps 8,333, 13,333, and 18,333. For the NIV dataset, with 50 diffusion steps, training lasts for 5,000 steps. The learning rate ramps up to \(3 \times 10^{-4}\) over the first 1,000 steps and is reduced by 50\% at steps 2,666 and 4,332. In the larger COIN dataset, we use 300 diffusion steps and train for 30,000 steps. The learning rate increases to \(1 \times 10^{-5}\) in the first 5,000 steps and is halved at steps 12,500, 20,000, and 27,500, stabilizing at \(2.5 \times 10^{-6}\) for the remaining steps. Training is performed using ADAM~\citep{kingma2014adam} on 8 NVIDIA RTX 3090 GPUs.


\subsection{Details of Uncertainty Modeling}
In the main paper, we investigate the probabilistic modeling capability of our model on the CrossTask and COIN datasets, demonstrating that our diffusion-based model can generate both diverse and accurate plans. Here, we provide additional details, results, and visualizations to further illustrate how our model handles uncertainty in procedure planning. 

\textbf{Details of Evaluating Uncertainty Modeling.} For the $Deterministic$ baseline, we sample once to obtain the plan, as the result is fixed when the observations and task class conditions are given. For the $Noise$ baseline and our diffusion-based model, we sample 1,500 action sequences to calculate the uncertainty metrics. To efficiently perform this process, we apply the DDIM~\citep{song2020denoising} sampling method to our model, enabling each sampling process to be completed in 10 steps. This accelerates sampling by 20 times for CrossTask and COIN, and by 5 times for NIV. It is important to note that multiple sampling is only required when evaluating probabilistic modelingâ€”our model can generate a good plan with just a single sample.

\begin{wraptable}{r}{0.45\textwidth}
\vspace{-5mm}
\centering
\caption{The results of uncertain modeling on the COIN dataset.}
\label{tab:unc-COIN}
\scalebox{0.87}{
\begin{tabular}{l l c c}
\toprule
Metric & Method & $T=3$ & $T=4$  \\ 
\midrule
\multirow{3}*{KL-Div $\downarrow$}
&  Deterministic & \textbf{4.47} & \textbf{4.40}\\ 
&  Noise & 5.12 & 4.88\\ 
&  Ours & \underline{4.74} & \underline{4.47} \\ 
\midrule
\multirow{3}*{NLL $\downarrow$}
&  Deterministic & \textbf{5.42} & \textbf{5.81}\\ 
&  Noise & 6.07 & 6.28\\ 
&  Ours & \underline{5.69} & \underline{5.87} \\ 
\midrule
\multirow{3}*{ModePrec $\uparrow$}
&  Deterministic & \textbf{34.04} & \textbf{32.47}\\ 
&  Noise & 23.16 & 22.18 \\ 
&  Ours & \underline{28.83} & \underline{26.91}\\
\midrule
\multirow{3}*{ModeRec $\uparrow$}
&  Deterministic & \textbf{27.41} & \textbf{20.88}\\ 
&  Noise & 21.06 & 15.24 \\ 
&  Ours & \underline{23.27} & \underline{18.14} \\
\bottomrule
\end{tabular}
}
\vspace{-7mm}
\end{wraptable}
\textbf{Additional Results on COIN.} Results on the COIN dataset are presented in \Cref{tab:unc-COIN}. On the COIN dataset, our model underperforms relative to the $Deterministic$ baseline. We attribute this to the shorter action sequences, where reduced uncertainty is more advantageous but less critical for long-horizon procedural planning.

\textbf{Visualizations for Uncertainty Modeling.} In \Cref{fig:visual3,fig:visual4,fig:visual5,fig:visual6}, we present visualizations of various plans with the same start and goal observations, generated by our masked temporal interpolation diffusion model on CrossTask for different prediction horizons. We have observed that some results contain repeated actions, which is due to the probabilistic nature of our model's prediction method, making repeated action predictions unavoidable. The top five predicted logits for the actions are passed through a softmax function, and the action with the highest probability is selected to form the prediction figures. 

\section{Baseline Methods}
In this section, we describe the baseline methods used in our study.
\begin{itemize}
    \item \textbf{Random Selection.} This method randomly selects actions from the available action space within the dataset to generate plans.
    \item \textbf{Retrieval-Based Approach.} Given the observations \(\{V_s, V_g\}\), this method retrieves the nearest neighbor by minimizing the visual feature distance within the training dataset. The action sequence associated with the retrieved neighbor is then used as the plan.
    \item \textbf{WLT DO \citep{ehsani2018let}.} This method employs a recurrent neural network (RNN) to predict action steps based on the provided observation pairs.
    \item \textbf{UAAA \citep{abu2019uncertainty}.} UAAA is a two-stage approach that uses an RNN-HMM model to predict action steps in an auto-regressive manner.
    \item \textbf{UPN \citep{srinivas2018universal}.} UPN is a path planning algorithm for physical environments that learns a plannable representation to generate predictions. To produce discrete action steps, a softmax layer is appended to the model's output, as described in \citep{chang2020procedure}.
    \item \textbf{DDN \citep{chang2020procedure}.} DDN is an auto-regressive framework with two branches designed to learn an abstract representation of action steps and predict transitions in the feature space.
    \item \textbf{PlaTe \citep{sun2022plate}.} PlaTe extends DDN by incorporating transformer modules into its two branches for prediction tasks. PlaTe uses a different evaluation protocol compared to other models.
    \item \textbf{Ext-GAIL \citep{bi2021procedure}.} Ext-GAIL addresses procedure planning using reinforcement learning. Unlike our approach, Ext-GAIL divides the planning problem into two stages: the first provides long-horizon information, which is then used by the second stage. In contrast, our approach derives sampling conditions directly.
    \item \textbf{P$^3$IV \citep{zhao2022p3iv}.} P$^3$IV is a transformer-based, single-branch model that incorporates a learnable memory bank and an additional generative adversarial framework. Similar to our model, P$^3$IV predicts all action steps simultaneously during inference.
    \item \textbf{PDPP \citep{wang2023pdpp}.} PDPP is a two-branch framework that models temporal dependencies and action transitions using a diffusion process. Like our model, PDPP predicts all actions simultaneously, refining predictions over multiple stages to enhance logical consistency during inference.
    \item \textbf{KEPP \citep{nagasinghe2024not}.} KEPP is a knowledge-enhanced procedure planning system that leverages a probabilistic procedural knowledge graph (P2KG) learned from training plans. This graph acts as a ``textbook'' to guide step sequencing in instructional videos. KEPP predicts all action steps simultaneously with minimal supervision, achieving leading performance.
    \item \textbf{SCHEMA \citep{niu2024schema}.} SCHEMA focuses on procedure planning by learning state transitions. It employs a transformer-based architecture with cross-modal contrastive learning to align visual inputs with text-based state descriptions. By tracking intermediate states, SCHEMA predicts future actions using a large language model to capture temporal dependencies and logical transitions, improving action planning in instructional videos.
\end{itemize}


\section{Additional Ablation Studies}

\textbf{Model Size.} Due to the large size of the COIN dataset, we adjust the model size by modifying the U-Net architecture. As shown in \Cref{tab:dm_combined}, increasing the model size results in higher scores for the COIN dataset. We believe that optimizing the model to be more memory-efficient could further improve performance, which we plan to explore in future work. In \Cref{tab:dm_combined}, increasing the size to 512 does not improve the scores on CrossTask. We believe this suggests overfitting, indicating that a model size of 256 is sufficient for this task.

\begin{table}[htbp]
\centering
\caption{Ablation study on the role of model size on COIN and CrossTask datasets.}
\vspace{2mm}
\scalebox{0.92}{
\begin{tabular}{llccccccc}
\toprule
& & \multicolumn{3}{c}{$T$ = 3} & & \multicolumn{3}{c}{$T$ = 4} \\ 
\cline{3-5} \cline{7-9}
Dataset & Size & SR$\uparrow$ & mAcc$\uparrow$ & mIoU$\uparrow$ & & SR$\uparrow$ & mAcc$\uparrow$ & mIoU$\uparrow$ \\ 
\midrule
\multirow{3}{*}{COIN} 
& 128 & 23.01 & 45.44 & 51.93 & & 19.69 & 45.32 & 55.06 \\
& 256 & \underline{28.84} & \underline{50.44} & \underline{57.86} & & \underline{21.64} & \underline{48.06} & \underline{59.52} \\
& 512 & \textbf{30.90} & \textbf{52.17} & \textbf{59.58} & & \textbf{23.10} & \textbf{49.71} & \textbf{60.78} \\
\midrule
\multirow{3}{*}{CrossTask} 
& 128 & 23.01 & 45.44 & 51.93 & & 19.69 & 45.32 & 55.06 \\
& 256 & \textbf{40.45} & \textbf{67.19} & \textbf{69.17} & & \textbf{24.76} & \textbf{60.69} & \textbf{67.67} \\
& 512 & \underline{37.94} & \underline{65.16} & \underline{67.43} & & \underline{21.97} & \underline{58.30} & \underline{66.15} \\
\bottomrule
\end{tabular}
}
\label{tab:dm_combined}
\end{table}

\begin{table}[htbp]
\centering
\caption{Ablation study on the observation encoder components ($T=3$, CrossTask).}
\vspace{2mm}
\scalebox{0.92}{
\begin{tabular}{lccc}
\toprule
Models & SR$\uparrow$ & mAcc$\uparrow$ & mIoU$\uparrow$ \\ 
\midrule
1 1d conv. layer w/ ReLU & \underline{39.71} & \underline{66.91} & \underline{69.05} \\
2 1d conv. layers w/ ReLU (Ours) & \textbf{40.45} & \textbf{67.19} & \textbf{69.17} \\
3 1d conv. layers w/ ReLU & 36.04 & 64.41 & 66.55 \\
1 1d conv. layer w/o ReLU & 39.32 & 66.70 & 68.91 \\
2 1d conv. layers w/o ReLU & 39.38 & 66.73 & 68.65 \\
3 1d conv. layers w/o ReLU & 37.77 & 65.06 & 67.61 \\
\bottomrule
\end{tabular}
}
\label{tab:encoder_layer}
\end{table}


\textbf{Components of Observation Encoder.} \Cref{tab:encoder_layer} presents the impact of different encoder components. Based on this ablation study, the optimal model consists of two 1D convolution layers with ReLU activation, which achieves the best balance between depth and activation, resulting in the highest scores across all metrics. Adding more layers does not consistently improve performance, and activation functions like ReLU play a key role in enhancing model effectiveness. We believe that ReLU introduces non-linearity, enabling the network to capture temporal latent features more effectively. Moreover, by setting negative values to zero, ReLU promotes sparse activation, which may aid in the extraction and construction of latent features.

\textbf{Transformer Classifier Type.} We conduct ablation studies on the CrossTask and COIN datasets to evaluate the impact of our transformer-based classifier. As shown in \Cref{tab:classifier_crosstask,tab:classifier_coin}, the inclusion of the transformer-based classifier significantly boosts the performance of PDPP. Although the improvements are modest for longer horizons, this highlights the effectiveness of our temporal interpolation module on CrossTask compared to PDPP with the same transformer classifier. However, the classifier's performance may also limit further improvements. Additionally, we observe that even with incorrect task class labels during supervision, the model still achieves strong scores, demonstrating its robustness, fault tolerance, and error correction capabilities. 



\begin{table}[t]
\centering
\caption{Ablation study on the role of classifier type on CrossTask dataset.}
\vspace{-3mm}
\scalebox{0.92}{
\begin{tabular}{lccccccccc}
\toprule
& \multicolumn{3}{c}{$T$ = 3} & & \multicolumn{3}{c}{$T$ = 4} & $T$=5 & $T$ = 6 \\ 
\cline{2-4} \cline{6-8}
{Models}          & SR$\uparrow$ & mAcc$\uparrow$   & mIoU$\uparrow$  &   & SR$\uparrow$    & mAcc$\uparrow$   & mIoU$\uparrow$  & SR$\uparrow$ & SR$\uparrow$ \\ \midrule
{PDPP (Res-MLP)}  & 37.2         & 55.35            & 66.57           &   & 21.48 &  57.82 &  65.13 &  13.58 &  8.47 \\
{PDPP (Transformer)}             & \underline{39.08} & \underline{66.32} & \underline{68.47}  &  &  \underline{22.48} &  \bf 60.72 &  \underline{66.13} &  \underline{13.77} &  \underline{8.63} \\
{MTID (Transformer)}    &   \bf 40.45 & \bf 67.19 & \bf 69.17  &  & \bf 24.76 & \underline{60.69} &  \bf 67.67 & \bf 15.26 & \bf 10.30 \\
\bottomrule
\end{tabular}
}
\label{tab:classifier_crosstask}
\end{table}

\input{figures/appendix_ablation1}

\begin{table}[htbp]
\centering
\caption{Ablation study on the role of classifier type on COIN dataset.}
\vspace{-3mm}
\scalebox{0.92}{
\begin{tabular}{lccccccc}
\toprule
& \multicolumn{3}{c}{$T$ = 3} & & \multicolumn{3}{c}{$T$ = 4} \\ 
\cline{2-4} \cline{6-8}
{Models}          & SR$\uparrow$ & mAcc$\uparrow$   & mIoU$\uparrow$  &   & SR$\uparrow$    & mAcc$\uparrow$   & mIoU$\uparrow$  \\ \midrule
{PDPP (Res-MLP)}             &   21.33   &   45.62 & 51.82 & & 14.41 & 44.10 & 51.39 \\
{PDPP (Transformer)} & \underline{24.02} & \underline{48.03} & \underline{55.21} & & \underline{17.36} & \underline{46.12} & \underline{55.82} \\
{MTID (Transformer)} &  \bf 28.84 & \bf 50.44 & \bf 57.86 & & \bf 21.64 & \bf 48.06 & \bf 59.52 \\
\bottomrule
\end{tabular}
}
\label{tab:classifier_coin}
\end{table}

\begin{figure}[ht]
    \centering
    \subfloat[Ablation studies on the number of transformer encoder block layers.]{
        \includegraphics[width=0.48\textwidth, keepaspectratio]{figures/ab1.png}
        \label{fig:num_trans}
    }
    \hfill
    \subfloat[Ablation studies on the scale of mask loss.]{
        \includegraphics[width=0.48\textwidth, keepaspectratio]{figures/ab2.png}
        \label{fig:scale_mask}
    }
    \hfill
    \subfloat[Ablation studies on the weights coefficient of loss.]{
        \includegraphics[width=0.48\textwidth, keepaspectratio]{figures/ab3.png}
        \label{fig:wei_coef}
    }
    \hfill
    \subfloat[ \textcolor{red}{ Accuracy changes of different actions at various time steps as epochs progress when T=5.} ]{
        \includegraphics[width=0.43\textwidth, keepaspectratio]{figures/output.png}
        \label{fig:actions}
    }
    \caption{Combined ablation studies of different coefficients. Note: ``t1'' refers to the number of transformer encoder layers in \Cref{fig:num_trans}; ``0.8'' represents the value of $\rho$ in loss function in \Cref{fig:scale_mask}; and ``w3'' indicates the value of the gradient-weighted loss $w_0$ in \Cref{fig:wei_coef}.   }
    \label{fig:combined}
    \vspace{-3mm}
\end{figure}

\textbf{More Interpolation Strategies.} We experimented with both linear and non-linear strategies, as shown in \Cref{fig:inxx3}. In \Cref{fig:inxx1}, we found that using a maximum value of `6' led to poor results, particularly for the ``square $\uparrow$'' and ``square $\downarrow$'' strategies, indicating a significant deviation from the desired final value. When we reduced the maximum value to `1', the results still remained unsatisfactory, suggesting that the final value of $\tau$ consistently converged around `1', resulting in sub-optimal performance.




\textbf{Number of Transformer Encoder Layers.} \Cref{fig:num_trans} shows the scores of three metrics across different numbers of layers in the transformer encoder blocks. The results indicate that using fewer layers (1 or 2) results in a significant drop in performance, with SR being the most adversely affected. As the number of layers increases, the metrics stabilize, with notable improvements, especially in SR, which shows a significant positive shift at 6 and 7 layers. In contrast, mAcc and mIoU show more subtle variations, with slight positive changes as the number of layers increases, reflecting a steady trend. These results suggest that an optimal configuration of 6 or 7 layers delivers the best overall performance.

\textbf{Scale of Mask Loss.} \Cref{fig:scale_mask} illustrates the impact of different values of $\rho$ on the loss function. We observe that when $\rho=1.3$, the scores are higher than for other values. Therefore, we adopt this value.

\textbf{Weight Coefficient of Loss.} \Cref{fig:wei_coef} shows the results for different values of $w_0$, the weight coefficient of the loss function. The results indicate that when $w_0$ is set to 7, the scores are higher than for other values. 


\begin{table}[htbp]
\centering
\caption{\textcolor{orange}{Performance comparison of T and M.}}
\label{tab:M_exp}
\scalebox{1.0}{
\begin{tabular}{lccc}
\toprule
\textbf{Method} & \textbf{SR$\uparrow$} & \textbf{mAcc$\uparrow$} & \textbf{mIoU$\uparrow$} \\ 
\midrule
T & 38.64 & 66.13 & 68.05 \\ 
M & \bf 40.45 & \bf 67.19 & \bf 69.17\\ 
\bottomrule
\end{tabular}
}
\end{table}


\begin{table}[htbp]
\caption{\textcolor{orange}{Ablation studies on different components on three datasets. Note: M: Our latent space temporal interpolation module, K: mask projection, L: task-adaptive masked proximity loss. The results of ID 1 are from PDPP. The setting on CrossTask is from PDPP, and on COIN and NIV is from KEPP.}}
\label{tab:dm_all}
\scalebox{0.94}{
\begin{tabular}{@{}cccc|ccc|ccc|ccc@{}}
\toprule
\multirow{2}{*}{ID} & \multirow{2}{*}{M} & \multirow{2}{*}{K} & \multirow{2}{*}{L} & \multicolumn{3}{c|}{CrossTask} & \multicolumn{3}{c|}{COIN} & \multicolumn{3}{c}{NIV} \\
\cmidrule{5-13}
& & & & SR$\uparrow$ & mAcc$\uparrow$ & mIoU$\uparrow$ & SR$\uparrow$ & mAcc$\uparrow$ & mIoU$\uparrow$ & SR$\uparrow$ & mAcc$\uparrow$ & mIoU$\uparrow$ \\
\midrule
1 &  &  &  & 37.20 & 64.67 & 66.57 & 19.42 & 43.44 & - & 22.22 & 39.50 & \color{gray}86.66 \\
2 & \checkmark &  &  & 39.03 & 66.49 & 68.26 & 28.80 & 50.20 & 58.51 & 25.56 & 37.65 & 50.78 \\ 
3 &  & \checkmark &  & 38.88 & 66.36 & 68.35 & 20.32 & 44.13 & 52.57 & 23.33 & 41.48 & 51.62 \\
4 &  &  & \checkmark & 38.57 & 66.02 & 68.17 & 25.63 & 48.03 & 56.88 & 24.44 & 42.47 & 54.46 \\
5 & \checkmark & \checkmark &  & 39.64 & \underline{66.74} & 68.77 & 29.25& 50.54 & 58.74 & 26.67 & \underline{43.95} & 54.17 \\
6 & \checkmark &  & \checkmark & \underline{39.71} & 66.65 & \underline{68.83} & \underline{29.46} & \underline{50.83} & \underline{58.84} & \underline{27.04} & 42.72 & \underline{54.5} \\
7 &  & \checkmark & \checkmark & 39.17 & 66.49 & 68.38  & 27.34 & 49.20 & 58.61  & 24.81 & 40.62 & 53.91 \\
8 & \checkmark & \checkmark & \checkmark & \textbf{40.45} & \textbf{67.19} & \textbf{69.17} & \textbf{30.44} & \textbf{51.70} & \textbf{59.74} 
 &\textbf{28.52} & \textbf{44.44} & \textbf{56.46} \\
\bottomrule
\end{tabular}
}
\end{table}
% 25.55555534362793 37.654319763183594 50.78395080566406
% 23.33333396911621 41.48147964477539 51.62345504760742
% 24.44444465637207 42.46913528442383 54.456790924072266
% 26.66666603088379 43.95061492919922 54.1728401184082
% 27.037036895751953 42.71604919433594 54.5
% 24.814815521240234 40.61728286743164 53.907405853271484

% 28.797616958618164 50.20117950439453 58.50629806518555
% 20.31666374206543 44.1343994140625 52.572242736816406
% 25.6309757232666 48.02737808227539 56.88064956665039
% 29.252233505249023 50.53561019897461 58.74327087402344
% 29.45602798461914 50.8282356262207 58.83680725097656
% 27.33970832824707 49.1978874206543 58.61341857910156

\textcolor{orange}{
\textbf{Ablation for Our Different Methods.}\Cref{tab:dm_all} presents the effects of our proposed methods. The results demonstrate that each component significantly enhances the model's performance.
}


\section{More Analysis for Methods}

\textcolor{orange}{
\textbf{More Explanation for $M$. }Our MTID diffusion model takes as input a matrix containing action sequences with T timesteps and is based on U-Net, which contains M residual temporal blocks in the downsampling, upsampling, and middle layers for directly diffusing and generating T intermediate target actions. To ensure that each intermediate layer contains valid auxiliary information, our Latent Space Temporal Interpolation Module needs to generate M intermediate auxiliary features. Subsequently, we apply cross-attention in residual temporal blocks across the M interpolated features and the entire input matrix rather than individual timesteps, enabling better temporal integration. We also conducted experiments to demonstrate the effect of M. Our results showed that using interpolated features only for T steps led to suboptimal performance. This also supports our decision to use interpolated features across all M modules.
}

% \textcolor{red}{
% \textbf{More Analysis for Mask and Gradient Weight in Our Loss Function.} From the experimental results in \Cref{tab:loss_ablation}, we can observe that the effect of adding a mask to different types of weights is not significant. From ID 3 to 6, the improvement is only 0.16. We believe this is because different types of weights impose restrictions on the start and end actions, which also emphasize task-specific actions, albeit indirectly. It can be said that there is an overlapping effect between the mask and the weights. This is also evident from the improvement from ID 1 to 2. Both the weights and mask contribute an improvement of two points in the results, and the case of ID = 6 demonstrates that their effects indeed overlap. Obviously, the objective of this task is to generate a completely accurate action sequence. The mask is designed to exclude actions that do not belong to this task. It should be noted that the remaining errors are due to repeated actions, different actions within the same task, and incorrect ordering, which means that the effect of excluding actions from other tasks is relatively limited. Addressing these remaining errors will be a focus of our future work.
% }

% \textcolor{red}{
% \textbf{More Explanation for Weighted Gradient Loss.} In PDPP, for handling the loss, a coefficient $w$ with a value of 10 is multiplied at the beginning and end positions. The paper believe that both sides are more important because they are the most related actions for the given observations. Experiments have shown that this approach is indeed effective. However, in my opinion, it doesn't better conform to the pattern of action accuracy. From my observations, I found that the accuracy tends to decrease for actions closer to the middle, but not identical in the middle as shown in~\Cref{fig:actions}. This is because the supervision from real visual features is stronger on both ends, while, as we move toward the middle, there is actually less available real information. Inspired by this, I designed a loss function that imposes stricter supervision constraints on both ends while relaxing the constraints in the middle, achieving better results.
% }

\textcolor{red}{
\textbf{Upper Bound of Visual Features Supervision.} The comparison presented in \Cref{tab:upbound} reveals that results vary depending on dataset characteristics, particularly size, task types, and average action sequence lengths. To explain this, we categorize our interpolated features into two parts: simple memory and hard temporal relationships. For instance, COIN, which has the largest dataset size but the shortest sequences, demonstrates that interpolated features excel in tasks focused on simple memory. In contrast, NIV, being the smallest dataset with the longest sequences, shows comparable performance between real and interpolated features. Meanwhile, CrossTask, characterized by large size and long sequences, exhibits a significant performance gap favoring real features. These findings highlight a trade-off where interpolated features perform well in simpler datasets but struggle with complex temporal relationships in larger, more diverse datasets. This underscores the necessity for improved interpolation methods to effectively manage complex, temporally diverse datasets in future research.
}

\begin{table}[htbp]
\centering
\caption{\textcolor{red}{Combined results for CrossTask, COIN, and NIV datasets with interpolated features and original real features.}}
\scalebox{0.91}{
\begin{tabular}{llccccccccc}
\toprule
& & \multicolumn{3}{c}{$T$ = 3} & & \multicolumn{3}{c}{$T$ = 4} & $T$=5 & $T$ = 6 \\ 
\cline{3-5} \cline{7-9}
{Dataset} & {Method}           & SR$\uparrow$    & mAcc$\uparrow$   & mIoU$\uparrow$  &   & SR$\uparrow$    & mAcc$\uparrow$   & mIoU$\uparrow$  & SR$\uparrow$ & SR$\uparrow$ \\ \midrule
\multirow{2}{*}{CrossTask}
& Interpolated             &   40.45 & 67.19 & 69.17  &  & 24.76 & 60.69 & 67.67 & 15.26 & 10.30 \\
& Real  &   \bf 49.05 & \bf 73.62 & \bf 73.23 &  & \bf 36.55 & \bf 70.42 & \bf 72.09 & \bf 24.88 & \bf 24.02 \\ \midrule
\multirow{2}{*}{COIN}
& Interpolated      &   \bf 30.90 & \bf 52.17 & \bf 59.58 & & \bf 23.10 & \bf 49.71 & \bf 60.78 & -- & -- \\
& Real  & 27.07 & 49.07 & 57.53 & & 20.01 & 47.35 & 58.24 & -- & -- \\ \midrule
\multirow{2}{*}{NIV}
& Interpolated      & 29.63 & 48.02 & \bf 56.49 & & \bf 25.76 & 46.62 & 58.50 & -- & -- \\
& Real & \bf 32.59 & \bf 50.25 & 56.40 & & 24.02 & \bf 48.36 & \bf 58.92 & -- & -- \\ 
\bottomrule
\end{tabular}
}
\label{tab:upbound}
\end{table}
% 49.050838470458984 73.6198959350586 73.22932434082031
% 36.55472946166992 70.42424774169922 72.08744049072266
% 24.87864112854004 67.00849914550781 70.32941436767578
% 24.028520584106445 68.59774017333984 73.76837158203125

% 27.073209762573242 49.07247543334961 57.53122329711914
% 20.011947631835938 47.346675872802734 58.24040985107422

% 32.592594146728516 50.246910095214844 56.4012336730957
% 24.017467498779297 48.36244583129883 58.919734954833984
\begin{figure}[htbp]
    \centering
    {\includegraphics[width=0.49\textwidth]{figures/feature_map1.png}\label{fig:fp1}}
    \hfill
    {\includegraphics[width=0.49\textwidth]{figures/feature_map2.png}\label{fig:fp2}}
    \caption{ \textcolor{blue}{Interpolated visual feature maps after downsampling and normalization with two different task matrices.} }
    \label{fig:fp}
\end{figure}



\textcolor{blue}{
\textbf{More Visualization Analysis for Interpolated Features.} 
\Cref{fig:fp} presents the M intermediate interpolated features. Due to the large size of the original features~(256,1536), we applied downsampling (selecting one out of every 40 points) and z-score normalization for visualization. From the figures, it is evident that while the overall patterns are consistent across tasks with similar information, the finer details vary according to differences in temporal logic and causal relationships.
}

\textcolor{orange}{
\textbf{Comparison with PDPP.} The results on COIN and NIV under the PDPP settings, as presented in Table~\Cref{tab:pdpp_mtid_comparison}, indicate that our performance on NIV is slightly lower due to two main factors. First, the dataset size of NIV is significantly smaller than that of CrossTask and COIN, which leads to the model excessively learning detailed patterns from the training data and consequently reducing its generalization ability. Second, there are differences in experimental settings: PDPP defines states as the window between start and end times, while KEPP uses a 2-second window around start and end times. This difference allows PDPP to access more step information, particularly for short-term actions, which may weaken the impact of our interpolation feature supplementation. Despite these challenges with NIV under PDPP settings, our model demonstrates strong capabilities on the larger CrossTask and COIN datasets, highlighting its effectiveness in temporal logic and memory utilization.
}

\begin{table}[htbp]
\centering
\caption{ \textcolor{orange}{Comparisons between PDPP and MTID under the setting of PDPP.} }
\vspace{-3mm}
\scriptsize
\scalebox{1.21}{
\begin{tabular}{p{1.0cm} @{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}
c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}
c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}
c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}
c@{\hspace{0.5em}}c@{\hspace{0.5em}}c@{\hspace{0.5em}}}
\toprule
\multicolumn{1}{c}{} & \multicolumn{7}{c}{\textbf{COIN}} & & \multicolumn{7}{c}{\textbf{NIV}} \\
\cmidrule(lr){2-8} \cmidrule(lr){10-16}
{Models}  & \multicolumn{3}{c}{$T$ = 3} & & \multicolumn{3}{c}{$T$ = 4} & & \multicolumn{3}{c}{$T$ = 3} & & \multicolumn{3}{c}{$T$ = 4} \\ 
\cline{2-4} \cline{6-8} \cline{10-12} \cline{14-16}
\multicolumn{1}{c}{} & SR$\uparrow$ & mAcc$\uparrow$ & mIoU$\uparrow$ & & SR$\uparrow$ & mAcc$\uparrow$ & mIoU$\uparrow$ & & SR$\uparrow$ & mAcc$\uparrow$ & mIoU$\uparrow$ & & SR$\uparrow$ & mAcc$\uparrow$ & mIoU$\uparrow$ \\
\midrule
PDPP & 21.33 & 45.62 & 51.82 & & 14.41 & 44.10 & 51.39 & & \bfseries 30.20 & \bfseries 48.45 & \bfseries 57.28 & & \bfseries 26.67 & \bfseries 46.89 & \bfseries 59.45 \\
MTID & \bfseries 30.90 & \bfseries 52.17 & \bfseries 59.58 & & \bfseries 23.10 & \bfseries 49.71 & \bfseries 60.78 & & 29.63 & 48.02 & 56.49 & & 25.76 & 46.62 & 58.50 \\
\bottomrule
\end{tabular}
}
\label{tab:pdpp_mtid_comparison}
\vspace{-4mm}
\end{table}

\section{Further Discussions}

\textbf{Limitations.} The limitations of our method are as follows. First, while the logical consistency between the actions generated by our model is generally strong, there is no guarantee of perfect alignment with the task. Mismatches were observed during the experiments, which is a common issue in procedure planning models. This challenge arises because the labels for multi-task and multi-action tasks in the dataset are replaced by data IDs, which may lead to issues with numerical calculations. 


\textbf{Comparison Across Supervision Strategies and Mid-State Handling.} Our MTID model introduces several innovations that set it apart in terms of how it handles supervision and mid-state action prediction:
(1) \textit{Supervision Approach: Weak vs. Full Supervision}:
DDN, PlaTe, and Ext-GAIL rely on fully supervised learning, requiring extensive annotations to model temporal dynamics. In contrast, MTID uses a weakly supervised approach with a latent space temporal interpolation module, capturing mid-state information without detailed annotations. Its diffusion process and latent interpolation offer finer-grained supervision for intermediate steps, outperforming Ext-GAIL and DDN in long-term predictions.
(2) \textit{Intermediate State Supervision and Logical Structure}:
PDPP uses task labels to bypass intermediate state supervision, and Skip-Plan reduces uncertainty by skipping uncertain intermediate actions. However, both methods struggle to fully capture the logical structure of intermediate steps. MTID addresses this by explicitly supervising mid-state actions through latent space interpolation, ensuring that the generated sequences are both temporally logical and well-aligned with the task requirements.
(3) \textit{Handling of External Knowledge and Probabilistic Guidance}:
P3IV leverages natural language instructions for weak supervision, while KEPP uses a probabilistic procedural knowledge graph (P2KG) to guide the planning process. While both methods aim to improve action prediction through external guidance, MTID distinguishes itself by focusing on direct mid-state supervision via intermediate latent features from a diffusion model. This approach provides more precise control over action generation, ensuring logical consistency across the entire sequence.
(4) \textit{State Representation and Visual Alignment}:
SCHEMA relies on large language models (LLMs) to describe and align state changes with visual observations, focusing on high-level state transitions. MTID, in contrast, directly uses mid-state supervision through latent space temporal interpolation, which improves visual-level supervision and enhances temporal reasoning, resulting in more accurate action sequence predictions.

\textbf{Generalization Capabilities.} Our MTID model demonstrates strong generalization across variations in action steps, object states, and environmental conditions. 
For action step variations, the model was evaluated with sequences of different lengths, ranging from 3 to 6 steps. 
The results consistently showed that MTID outperforms state-of-the-art models, leveraging its latent space temporal interpolation to capture temporal relationships across various step lengths. 
In terms of object states and environmental contexts, the benchmark datasets used for evaluation cover a wide range of topics, such as cooking, housework, and car maintenance, featuring diverse objects like fruits, drinks, and household items. 
For instance, the CrossTask dataset includes \textcolor{orange}{105} step types across 18 tasks, while the COIN dataset features 778 step types over 180 tasks. 
These tests highlight MTID's ability to generalize effectively, capturing the nuances of varying object states and environmental conditions, due to its robust interpolation and diffusion framework.

\input{figures/visual}